{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from coverage import gen_sats, gen_times, camera_model, forecast_fovs, calculate_revisits, revisit_map\n",
    "from datetime import datetime, timezone, timedelta\n",
    "import dataclasses\n",
    "from shapely.geometry import Point\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import branca\n",
    "import folium\n",
    "\n",
    "from skyfield.framelib import itrs\n",
    "from landsat import Instrument, Platform, Scene\n",
    "\n",
    "! mkdir tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_dt = datetime.fromisoformat(Scene.start_utc)\n",
    "num_days = 2\n",
    "\n",
    "tles = gen_sats(\n",
    "    sat_nos=[Platform.norad_id] # How to best handle multiple platforms? (TLE vs. SPG4 model too)\n",
    "    # sat_nos=[39084]\n",
    "    # sat_nos=[39084,49260]\n",
    ")\n",
    "\n",
    "inst = camera_model(\n",
    "    name=Instrument.name, \n",
    "    fl=Instrument.focal_length_mm, \n",
    "    pitch=Instrument.pitch_um*1e-3, \n",
    "    h_pix=Instrument.rows, \n",
    "    v_pix=Instrument.cols, \n",
    ")\n",
    "\n",
    "times = gen_times(\n",
    "    start_yr=start_dt.year,\n",
    "    start_mo=start_dt.month, \n",
    "    start_day=start_dt.day, \n",
    "    days=num_days, \n",
    "    step_min=Instrument.img_period)\n",
    "\n",
    "xcell_size = ycell_size = .1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Batch FOV generation over N satellites - TODO: build multiple sats into config/ main script\n",
    "gdfs = []\n",
    "for tle in tles:\n",
    "    sat = tle[0]\n",
    "\n",
    "    fov_df = forecast_fovs(sat, times, inst)\n",
    "    xyz_dist_rates = sat.at(times).frame_xyz_and_velocity(itrs)\n",
    "    fov_df['x_pos'], fov_df['y_pos'], fov_df['z_pos'] = xyz_dist_rates[0].km\n",
    "    fov_df['x_vel'], fov_df['y_vel'], fov_df['z_vel'] = xyz_dist_rates[1].km_per_s\n",
    "    gdfs.append(fov_df)\n",
    "\n",
    "fov_df = gpd.GeoDataFrame(pd.concat(gdfs, ignore_index=True), crs=\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fov_df[\"frac_days\"] = fov_df.datetime.dt.dayofweek + fov_df.datetime.dt.hour/24 + fov_df.datetime.dt.minute/(24*60) + fov_df.datetime.dt.second/(24*60*60)\n",
    "fov_df['time_gap'] = fov_df['frac_days'] - fov_df['frac_days'].shift(1)\n",
    "fov_df[[\"datetime\", \"satellite\", \"id\", \"time\", \"geometry\"]].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "# get_inst_fov(sat, times[0], inst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set ascending/ descending direction\n",
    "conditions = [\n",
    "    fov_df['z_vel'].lt(0),\n",
    "    fov_df['z_vel'].gt(0)\n",
    "]\n",
    "\n",
    "choices = ['dsc','asc']\n",
    "fov_df['asc_dsc'] = np.select(conditions, choices, default='undefined')\n",
    "\n",
    "## Drop ascending pass FOVs\n",
    "fov_df.loc[fov_df.asc_dsc==\"asc\", \"geometry\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Select AOI from gpd naturalearth dataset (filter by .name for country, .continent for continent)\n",
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "\n",
    "# Drop Antarctica\n",
    "world = world[world.continent != \"Antarctica\"]\n",
    "\n",
    "## Drop any FOVs not over land area\n",
    "join = fov_df.sjoin(world, how=\"left\").dropna()\n",
    "fov_df.loc[join.index, 'mode'] = \"SCIENCE\"\n",
    "fov_df.loc[~fov_df.index.isin(join.index), 'mode'] = \"STANDBY\"\n",
    "fov_df.loc[fov_df['mode']==\"STANDBY\", \"geometry\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plotting FOVs\n",
    "\n",
    "## Create cmap for unique satellites and create color column\n",
    "## TODO: Move to plotting function?\n",
    "sat_ids = list(fov_df[\"id\"].unique()).sort()\n",
    "cmap = branca.colormap.StepColormap(['red', 'blue'], sat_ids, vmin=139084, vmax = 149260)\n",
    "fov_df['color'] = fov_df['id'].apply(cmap)\n",
    "\n",
    "## Make a folium map\n",
    "m = fov_df[fov_df['mode']==\"SCIENCE\"].drop('datetime', axis=1).explore(color=\"color\", style_kwds={'fillOpacity':0.2}, tooltip=[\"satellite\", \"time\"])\n",
    "\n",
    "## View or save\n",
    "m#.save(\"./tmp/fovs_map.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Coverage data analysis for single satellite/ batch of satellites\n",
    "\n",
    "## Set AOI\n",
    "# aoi =  world[world.name == \"Brazil\"].geometry\n",
    "# aoi =  world[world.continent == \"North America\"].geometry\n",
    "# aoi = world[world.name == \"United States of America\"].geometry # Includes Alaska...\n",
    "\n",
    "## Or read in aoi from .geojson\n",
    "aoi = gpd.read_file('./aois/eastern_us.geojson').geometry # ...so use AOI for subsection of US\n",
    "\n",
    "## Filter fov_df by aoi\n",
    "xmin, ymin, xmax, ymax= aoi.total_bounds\n",
    "revisit_df = fov_df.cx[xmin: xmax, ymin: ymax]\n",
    "\n",
    "## Create revisit map on regular grid\n",
    "grid, grid_shape = calculate_revisits(revisit_df, aoi, grid_x=xcell_size, grid_y=ycell_size)\n",
    "grid.n_visits.fillna(0).describe()\n",
    "m = revisit_map(grid, grid_shape, grid_x=xcell_size, grid_y=ycell_size)\n",
    "\n",
    "# Add WRS2 - Only use with AOI applied!\n",
    "wrs2 = gpd.read_file('./WRS2_descending_0/WRS2_descending.shp')\n",
    "wrs2 = wrs2.cx[xmin: xmax, ymin: ymax]\n",
    "folium.GeoJson(data=wrs2[\"geometry\"], overlay=False).add_to(m)\n",
    "\n",
    "m#.save(\"./tmp/revisits_map.html\")\n",
    "\n",
    "# TODO: Fix Landsat image timing to match WRS-2 grid, as described here: https://landsat.gsfc.nasa.gov/about/the-worldwide-reference-system/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fix saves to GeoJSON (done using patch below)\n",
    "import fiona\n",
    "\n",
    "# grid.to_file('./tmp/all_revisits.geojson')\n",
    "\n",
    "save_df = fov_df.loc[:,['satellite', 'geometry', 'time']].dropna()\n",
    "save_df['satellite'] = save_df[\"satellite\"].astype(str)\n",
    "save_df['time'] = save_df[\"time\"].astype(str)\n",
    "\n",
    "## Save to geojson based on sat name\n",
    "for satname in save_df.satellite.unique():\n",
    "    with fiona.Env(OSR_WKT_FORMAT=\"WKT2_2018\"):\n",
    "        save_df[save_df.satellite==satname].to_file(\"./tmp/{}_fovs.geojson\".format(satname.replace(\" \", \"_\")), engine=\"pyogrio\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e08235b3b3f261cce032f41d2f5ba53bea32df87899ea41a1c550ca660aae0c9"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('coverage')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
